{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ba480d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8df9fa8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/netscratch2/lmeynent/research/structure_vs_behaviour/zoo_utils.py:6: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "from utils import test_model, compare_models_prediction, generate_z_samples\n",
    "from zoo_utils import load_hyperrep_edx\n",
    "\n",
    "from shrp.models.def_net import CNN, CNN3\n",
    "from shrp.models.def_AE_trainable import get_transformations\n",
    "from shrp.datasets.dataset_auxiliaries import tokens_to_recipe, tokens_to_checkpoint\n",
    "from shrp.models.def_loss import DistillationLoss, ReconDistillationLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28c05d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(context='notebook', style='whitegrid',\n",
    "              rc={\n",
    "                  'axes.spines.right': False,\n",
    "                  'axes.spines.top': False,\n",
    "                  'xtick.bottom': True,\n",
    "                  'ytick.left': True,\n",
    "                  'font.family': 'Fira Sans'\n",
    "              })\n",
    "\n",
    "COLOURS = [\n",
    "    '#960018',  # Carmine Red\n",
    "    '#FED85D',  # Mustard Gold\n",
    "    '#434384',  # Marian Blue\n",
    "    '#54B674',  # Emerald Green\n",
    "    '#D183C9',  # French Mauve\n",
    "    '#318CE7',  # French Blue\n",
    "    '#D08000'   # Fulvous Orange\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d5f8fc",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2792e754",
   "metadata": {},
   "outputs": [],
   "source": [
    "RERUN = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efacef1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = ['svhn', 'cifar10', 'eurosat']\n",
    "DATASET_LABELS = {\n",
    "    'svhn': 'SVHN',\n",
    "    'cifar10': 'CIFAR-10',\n",
    "    'eurosat': 'EuroSAT'\n",
    "}\n",
    "\n",
    "DS_ORDER = ['SVHN', 'CIFAR-10', 'EuroSAT']\n",
    "HR_ORDER = ['Contrastive + Structure (Baseline)', 'Behavior', 'Contrastive + Behavior', 'Structure + Behavior', 'Contrastive + Structure + Behavior']\n",
    "HR_PLOT = ['Contrastive + Structure (Baseline)', 'Contrastive + Behavior', 'Contrastive + Structure + Behavior']\n",
    "\n",
    "EXPERIMENT_PATH = Path.cwd() / 'results' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "921258d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model zoo train set\n",
    "TRAINSET_DS = {ds: torch.load(f'/netscratch2/lmeynent/research/structure_vs_behaviour/results/data/{ds}_train_zoo_relu/dataset.pt')['trainset'] for ds in DATASETS}\n",
    "TRAINSET_DL = {ds: torch.utils.data.DataLoader(TRAINSET_DS[ds], batch_size=64, shuffle=True) for ds in DATASETS}\n",
    "\n",
    "# Test set corresponding to the data used to train the model zoo\n",
    "TESTSET_DS = {ds: torch.load(f'/netscratch2/lmeynent/research/structure_vs_behaviour/results/data/{ds}_train_zoo_relu/dataset.pt')['testset'] for ds in DATASETS}\n",
    "TESTSET_DL = {ds: torch.utils.data.DataLoader(TESTSET_DS[ds], batch_size=64, shuffle=False) for ds in DATASETS}\n",
    "\n",
    "# Model zoo\n",
    "ZOO_PATH = {ds: Path(f'/netscratch2/lmeynent/research/structure_vs_behaviour/results/zoos/{ds}_train_zoo_relu') for ds in DATASETS}\n",
    "ZOO_DS = {ds: torch.load(ZOO_PATH[ds] / 'dataset_test.pt') for ds in DATASETS}\n",
    "ZOO_DL = {ds: torch.utils.data.DataLoader(ZOO_DS[ds], batch_size=16, shuffle=False) for ds in DATASETS}\n",
    "\n",
    "ZOO_DS_TRAIN = {ds: torch.load(ZOO_PATH[ds] / 'dataset_train.pt') for ds in DATASETS}\n",
    "ZOO_DL_TRAIN = {ds: torch.utils.data.DataLoader(ZOO_DS[ds], batch_size=16, shuffle=False) for ds in DATASETS}\n",
    "\n",
    "# Threshold used to define models that \"perform well\"; depends on the zoo\n",
    "MODEL_ACC_THR = {\n",
    "    'svhn': 0.8,\n",
    "    'cifar10': 0.6,\n",
    "    'eurosat': 0.7\n",
    "}\n",
    "\n",
    "# Path to the hyper-representation models\n",
    "HYPERREP_PATH = {ds: Path(f'/netscratch2/lmeynent/research/structure_vs_behaviour/results/hyperrepresentations/tune/{ds}_train_hyperrep') for ds in DATASETS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "004bf680",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_DIM_1, X_DIM_2 = next(iter(ZOO_DL['svhn']))[0].shape[1:3]\n",
    "X_COLS = [f'Dimension {i}' for i in range(X_DIM_1 * X_DIM_2)]\n",
    "\n",
    "Z_DIM_1 = X_DIM_1\n",
    "Z_DIM_2 = 64\n",
    "Z_COLS = [f'Dimension {i}' for i in range(Z_DIM_1 * Z_DIM_2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aec02075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acc963c9afe8427fa6b5dc28e8bb5277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading data:   0%|          | 0/3 [00:00<?, ?dataset/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model zoo</th>\n",
       "      <th>Trial ID</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Latent dimension</th>\n",
       "      <th>Behaviour loss</th>\n",
       "      <th>Query set</th>\n",
       "      <th>Query dataset</th>\n",
       "      <th># of queries</th>\n",
       "      <th>Gamma</th>\n",
       "      <th>Beta</th>\n",
       "      <th>...</th>\n",
       "      <th>Train loss (recon)</th>\n",
       "      <th>Train loss (structure)</th>\n",
       "      <th>Train loss (behaviour)</th>\n",
       "      <th>Test loss</th>\n",
       "      <th>Test loss (contrast)</th>\n",
       "      <th>Test loss (recon)</th>\n",
       "      <th>Test loss (structure)</th>\n",
       "      <th>Test loss (behaviour)</th>\n",
       "      <th>Dstk: Test accuracy</th>\n",
       "      <th>Dstk: GGap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVHN</td>\n",
       "      <td>50f57_00020</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>64</td>\n",
       "      <td>cross_entropy</td>\n",
       "      <td>data</td>\n",
       "      <td>SVHN</td>\n",
       "      <td>256</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.344194</td>\n",
       "      <td>0.930796</td>\n",
       "      <td>1.390127</td>\n",
       "      <td>1.059503</td>\n",
       "      <td>1.045855</td>\n",
       "      <td>1.060222</td>\n",
       "      <td>0.791913</td>\n",
       "      <td>1.090034</td>\n",
       "      <td>0.559680</td>\n",
       "      <td>0.283559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVHN</td>\n",
       "      <td>50f57_00020</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>64</td>\n",
       "      <td>cross_entropy</td>\n",
       "      <td>data</td>\n",
       "      <td>SVHN</td>\n",
       "      <td>256</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.275532</td>\n",
       "      <td>0.770928</td>\n",
       "      <td>0.220488</td>\n",
       "      <td>0.257198</td>\n",
       "      <td>0.887651</td>\n",
       "      <td>0.224016</td>\n",
       "      <td>0.591360</td>\n",
       "      <td>0.183200</td>\n",
       "      <td>0.554503</td>\n",
       "      <td>0.276677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVHN</td>\n",
       "      <td>50f57_00020</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>64</td>\n",
       "      <td>cross_entropy</td>\n",
       "      <td>data</td>\n",
       "      <td>SVHN</td>\n",
       "      <td>256</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266038</td>\n",
       "      <td>0.677502</td>\n",
       "      <td>0.220320</td>\n",
       "      <td>0.247892</td>\n",
       "      <td>0.708432</td>\n",
       "      <td>0.223653</td>\n",
       "      <td>0.544859</td>\n",
       "      <td>0.187963</td>\n",
       "      <td>0.550643</td>\n",
       "      <td>0.276275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVHN</td>\n",
       "      <td>50f57_00020</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>64</td>\n",
       "      <td>cross_entropy</td>\n",
       "      <td>data</td>\n",
       "      <td>SVHN</td>\n",
       "      <td>256</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.264123</td>\n",
       "      <td>0.664841</td>\n",
       "      <td>0.219599</td>\n",
       "      <td>0.239949</td>\n",
       "      <td>0.652948</td>\n",
       "      <td>0.218212</td>\n",
       "      <td>0.527920</td>\n",
       "      <td>0.183800</td>\n",
       "      <td>0.551713</td>\n",
       "      <td>0.279411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVHN</td>\n",
       "      <td>50f57_00020</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>64</td>\n",
       "      <td>cross_entropy</td>\n",
       "      <td>data</td>\n",
       "      <td>SVHN</td>\n",
       "      <td>256</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261248</td>\n",
       "      <td>0.628665</td>\n",
       "      <td>0.220424</td>\n",
       "      <td>0.242219</td>\n",
       "      <td>0.741064</td>\n",
       "      <td>0.215964</td>\n",
       "      <td>0.495595</td>\n",
       "      <td>0.184894</td>\n",
       "      <td>0.538348</td>\n",
       "      <td>0.282729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model zoo     Trial ID  Learning rate  Latent dimension Behaviour loss  \\\n",
       "0      SVHN  50f57_00020        0.00001                64  cross_entropy   \n",
       "1      SVHN  50f57_00020        0.00001                64  cross_entropy   \n",
       "2      SVHN  50f57_00020        0.00001                64  cross_entropy   \n",
       "3      SVHN  50f57_00020        0.00001                64  cross_entropy   \n",
       "4      SVHN  50f57_00020        0.00001                64  cross_entropy   \n",
       "\n",
       "  Query set Query dataset  # of queries  Gamma  Beta  ...  Train loss (recon)  \\\n",
       "0      data          SVHN           256   0.05   0.1  ...            1.344194   \n",
       "1      data          SVHN           256   0.05   0.1  ...            0.275532   \n",
       "2      data          SVHN           256   0.05   0.1  ...            0.266038   \n",
       "3      data          SVHN           256   0.05   0.1  ...            0.264123   \n",
       "4      data          SVHN           256   0.05   0.1  ...            0.261248   \n",
       "\n",
       "   Train loss (structure)  Train loss (behaviour)  Test loss  \\\n",
       "0                0.930796                1.390127   1.059503   \n",
       "1                0.770928                0.220488   0.257198   \n",
       "2                0.677502                0.220320   0.247892   \n",
       "3                0.664841                0.219599   0.239949   \n",
       "4                0.628665                0.220424   0.242219   \n",
       "\n",
       "   Test loss (contrast)  Test loss (recon)  Test loss (structure)  \\\n",
       "0              1.045855           1.060222               0.791913   \n",
       "1              0.887651           0.224016               0.591360   \n",
       "2              0.708432           0.223653               0.544859   \n",
       "3              0.652948           0.218212               0.527920   \n",
       "4              0.741064           0.215964               0.495595   \n",
       "\n",
       "   Test loss (behaviour)  Dstk: Test accuracy  Dstk: GGap  \n",
       "0               1.090034             0.559680    0.283559  \n",
       "1               0.183200             0.554503    0.276677  \n",
       "2               0.187963             0.550643    0.276275  \n",
       "3               0.183800             0.551713    0.279411  \n",
       "4               0.184894             0.538348    0.282729  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_EPOCH = 100\n",
    "\n",
    "df_hr = pd.DataFrame(columns=[\n",
    "    'Model zoo',\n",
    "    'Trial ID',\n",
    "    'Learning rate',\n",
    "    'Latent dimension',\n",
    "    'Behaviour loss',\n",
    "    'Query set',\n",
    "    'Query dataset',\n",
    "    '# of queries',\n",
    "    'Gamma',\n",
    "    'Beta',\n",
    "    'Epoch',\n",
    "    'Train loss',\n",
    "    'Train loss (contrast)', \n",
    "    'Train loss (recon)',\n",
    "    'Train loss (structure)', \n",
    "    'Train loss (behaviour)',\n",
    "    'Test loss',\n",
    "    'Test loss (contrast)', \n",
    "    'Test loss (recon)',\n",
    "    'Test loss (structure)', \n",
    "    'Test loss (behaviour)',\n",
    "    'Dstk: Test accuracy',\n",
    "    'Dstk: GGap'\n",
    "])\n",
    "\n",
    "for ds in tqdm(DATASETS, desc='Loading data', unit='dataset'):\n",
    "    hr_path = HYPERREP_PATH[ds]\n",
    "    for path in os.listdir(hr_path):\n",
    "        if not re.match('AE_trainable', path):\n",
    "            continue\n",
    "        path = hr_path / path\n",
    "\n",
    "        with open(path / 'params.json') as ifh_config, open(path / 'result.json') as ifh_result:\n",
    "            config = json.load(ifh_config)\n",
    "            result = pd.read_json(ifh_result, lines=True, dtype={'trial_id': str})\n",
    "\n",
    "        for edx in range(len(result)):\n",
    "            df_hr.loc[len(df_hr)] = (\n",
    "                DATASET_LABELS[ds],\n",
    "                result.loc[edx]['trial_id'],\n",
    "                config['optim::lr'],\n",
    "                config['ae:lat_dim'],\n",
    "                config['training::loss_distillation'],\n",
    "                config['training::queryset_distillation'],\n",
    "                config['training::queryset_dump'],\n",
    "                config['training::n_queries_distillation'],\n",
    "                config['training::gamma'],\n",
    "                config['training::beta'],\n",
    "                result.loc[edx]['training_iteration'],\n",
    "                result.loc[edx]['loss/loss_train'],\n",
    "                result.loc[edx]['loss/loss_contrast_train'],\n",
    "                result.loc[edx]['loss/loss_recon_train'],\n",
    "                result.loc[edx]['loss/loss_structure_train'],\n",
    "                result.loc[edx]['loss/loss_behaviour_train'],\n",
    "                result.loc[edx]['loss/loss_test'],\n",
    "                result.loc[edx]['loss/loss_contrast_test'],\n",
    "                result.loc[edx]['loss/loss_recon_test'],\n",
    "                result.loc[edx]['loss/loss_structure_test'],\n",
    "                result.loc[edx]['loss/loss_behaviour_test'],\n",
    "                result.loc[edx]['dstk/test_acc_test'],\n",
    "                result.loc[edx]['dstk/ggap_test']\n",
    "            )\n",
    "\n",
    "df_hr['Query dataset'] = df_hr['Query dataset'].map({\n",
    "    '/netscratch2/lmeynent/research/structure_vs_behaviour/results/data/svhn_train_zoo_relu/dataset.pt': 'SVHN',\n",
    "    '/netscratch2/lmeynent/research/structure_vs_behaviour/results/data/cifar10_train_zoo_relu/dataset.pt': 'CIFAR-10',\n",
    "    '/netscratch2/lmeynent/research/structure_vs_behaviour/results/data/eurosat_train_zoo_relu/dataset.pt': 'EuroSAT',\n",
    "    '/netscratch2/lmeynent/research/structure_vs_behaviour/results/data/tinyimagenet_32/dataset.pt': 'TinyImagenet-32'\n",
    "})\n",
    "df_hr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6f2b28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svhn': {'50f57_00011': 'Contrastive + Structure (Baseline)',\n",
       "  '50f57_00008': 'Contrastive + Structure + Behavior'},\n",
       " 'cifar10': {'0d5ff_00011': 'Contrastive + Structure (Baseline)',\n",
       "  '0d5ff_00008': 'Contrastive + Structure + Behavior'},\n",
       " 'eurosat': {'d28cf_00011': 'Contrastive + Structure (Baseline)',\n",
       "  'd28cf_00008': 'Contrastive + Structure + Behavior'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IDX_DICT = {ds:\n",
    "    {\n",
    "        df_hr[(df_hr['Model zoo'] == DATASET_LABELS[ds]) & (df_hr['Learning rate'] == 1e-4) & (df_hr['Gamma'] == 0.05) & (df_hr['Beta'] == 1.0) & (df_hr['Behaviour loss'] == 'l2')]['Trial ID'].iloc[0]: 'Contrastive + Structure (Baseline)',\n",
    "        df_hr[(df_hr['Model zoo'] == DATASET_LABELS[ds]) & (df_hr['Learning rate'] == 1e-5) & (df_hr['Gamma'] == 0.05) & (df_hr['Beta'] == 0.1) & (df_hr['Behaviour loss'] == 'l2')]['Trial ID'].iloc[0]: 'Contrastive + Structure + Behavior'\n",
    "    }\n",
    "    for ds in DATASETS\n",
    "}\n",
    "IDX_DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "621b1fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading reference config\n",
    "trial_id = df_hr.iloc[0]['Trial ID']\n",
    "for path in os.listdir(HYPERREP_PATH['svhn']):\n",
    "    if trial_id in path:\n",
    "        model_path = HYPERREP_PATH['svhn'] / path\n",
    "        with open(HYPERREP_PATH['svhn'] / path / 'params.json') as ifh:\n",
    "            ref_config = json.load(ifh)\n",
    "\n",
    "# Loading reference params\n",
    "ref_path = ref_config[\"training::distil_reference\"]\n",
    "with open(os.path.join(ref_path, 'params.json')) as ifh:\n",
    "    reference_params = json.load(ifh)\n",
    "    \n",
    "# Loading reference checkpoint\n",
    "ref_chkpth = None\n",
    "for chkpth in os.listdir(ref_path):\n",
    "    if 'checkpoint_' in chkpth:\n",
    "        if not ref_chkpth or int(chkpth.split('_')[-1]) > int(ref_chkpth.split('_')[-1]):\n",
    "            ref_chkpth = chkpth\n",
    "\n",
    "reference_checkpoint = torch.load(Path(ref_path) / str(ref_chkpth) / 'checkpoints', map_location=torch.device(\"cpu\"))\n",
    "reference_checkpoint_cuda = {k: v.to('cuda') for k, v in deepcopy(reference_checkpoint).items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2bdcc5",
   "metadata": {},
   "source": [
    "### Loading hyper-representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "380d503d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading hyper-reps\n",
    "def load_hr(trial_id):\n",
    "    for ds in DATASETS:\n",
    "        for path in os.listdir(HYPERREP_PATH[ds]):\n",
    "            if trial_id in path:\n",
    "                return load_hyperrep_edx(HYPERREP_PATH[ds] / path, MAX_EPOCH)\n",
    "\n",
    "hyper_reps = {idx: load_hr(idx) for idx in df_hr['Trial ID'].unique()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b21f97c",
   "metadata": {},
   "source": [
    "### Loading model zoos metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc5ad357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model zoo</th>\n",
       "      <th>Trial ID</th>\n",
       "      <th>Activation function</th>\n",
       "      <th>Initialisation</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Weight decay</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Test accuracy</th>\n",
       "      <th>Generalisation gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVHN</td>\n",
       "      <td>7597300394</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform</td>\n",
       "      <td>0.00075</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.071758</td>\n",
       "      <td>-0.001563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVHN</td>\n",
       "      <td>7597300394</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform</td>\n",
       "      <td>0.00075</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.775200</td>\n",
       "      <td>-0.182034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVHN</td>\n",
       "      <td>7597300394</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform</td>\n",
       "      <td>0.00075</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.829479</td>\n",
       "      <td>-0.016614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVHN</td>\n",
       "      <td>7597300394</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform</td>\n",
       "      <td>0.00075</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.846381</td>\n",
       "      <td>-0.003682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVHN</td>\n",
       "      <td>7597300394</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform</td>\n",
       "      <td>0.00075</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.848033</td>\n",
       "      <td>0.010410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model zoo    Trial ID Activation function   Initialisation  Learning rate  \\\n",
       "0      SVHN  7597300394                relu  kaiming_uniform        0.00075   \n",
       "1      SVHN  7597300394                relu  kaiming_uniform        0.00075   \n",
       "2      SVHN  7597300394                relu  kaiming_uniform        0.00075   \n",
       "3      SVHN  7597300394                relu  kaiming_uniform        0.00075   \n",
       "4      SVHN  7597300394                relu  kaiming_uniform        0.00075   \n",
       "\n",
       "   Weight decay  Seed  Epoch  Test accuracy  Generalisation gap  \n",
       "0        0.0005     6      0       0.071758           -0.001563  \n",
       "1        0.0005     6      1       0.775200           -0.182034  \n",
       "2        0.0005     6      2       0.829479           -0.016614  \n",
       "3        0.0005     6      3       0.846381           -0.003682  \n",
       "4        0.0005     6      4       0.848033            0.010410  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_ZOO_PATH = EXPERIMENT_PATH / 'zoo_analysis' / 'df_zoo.csv'\n",
    "\n",
    "df_zoo = pd.read_csv(DF_ZOO_PATH, index_col=0)\n",
    "df_zoo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cd9517",
   "metadata": {},
   "source": [
    "## Running experiments\n",
    "\n",
    "Hyper-representation model: `CIFAR-10`\\\n",
    "Models: `SVHN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65724284",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_PATH = EXPERIMENT_PATH / 'ablation_ood_generation'\n",
    "\n",
    "if not (EXPERIMENT_PATH).is_dir():\n",
    "    os.makedirs(EXPERIMENT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06645d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a36ede01d3a49cc8a465fea857d68df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DF_ZOO_ACC_PATH = EXPERIMENT_PATH / 'df_zoo_acc.csv'\n",
    "DF_Z_PATH = EXPERIMENT_PATH / 'df_z_dict.csv'\n",
    "DF_X_PATH = EXPERIMENT_PATH / 'df_x_dict.csv'\n",
    "\n",
    "X_DIM_1, X_DIM_2 = next(iter(ZOO_DL['svhn']))[0].shape[1:3]\n",
    "X_COLS = [f'Dimension {i}' for i in range(X_DIM_1 * X_DIM_2)]\n",
    "\n",
    "Z_DIM_1 = X_DIM_1\n",
    "Z_DIM_2 = 64\n",
    "Z_COLS = [f'Dimension {i}' for i in range(Z_DIM_1 * Z_DIM_2)]\n",
    "\n",
    "if not DF_ZOO_ACC_PATH.is_file() or RERUN:\n",
    "    # Create dataframe\n",
    "    df_zoo_acc = pd.DataFrame(columns=['Model index', 'Hyper-representation model', 'Original accuracy', 'Reconstruction accuracy'])\n",
    "    df_x = pd.DataFrame(columns=['Model index', 'Hyper-representation model'] + X_COLS)\n",
    "    df_z = pd.DataFrame(columns=['Model index', 'Hyper-representation model'] + Z_COLS)\n",
    "\n",
    "    # Run experiments\n",
    "    for bdx, data in enumerate(tqdm(ZOO_DL['svhn'])):\n",
    "        x, m, p, _ = data\n",
    "\n",
    "        for hr_idx, hr_label in IDX_DICT['cifar10'].items():\n",
    "            z, y, _ = hyper_reps[hr_idx].forward(x, p)\n",
    "            \n",
    "            for idx in range(x.shape[0]):\n",
    "                # Original accuracy\n",
    "                orig_checkpoint = tokens_to_checkpoint(x[idx], p[idx], reference_checkpoint)\n",
    "                orig_model = CNN3(\n",
    "                    channels_in=reference_params['model::channels_in'],\n",
    "                    nlin=reference_params['model::nlin'],\n",
    "                    dropout=reference_params['model::dropout']\n",
    "                )\n",
    "                orig_model.load_state_dict(orig_checkpoint)\n",
    "                orig_acc = test_model(orig_model, TESTSET_DL['svhn'])\n",
    "                \n",
    "                # Reconstruction accuracy\n",
    "                recon_checkpoint = tokens_to_checkpoint(y[idx], p[idx], reference_checkpoint)\n",
    "                recon_model = CNN3(\n",
    "                    channels_in=reference_params['model::channels_in'],\n",
    "                    nlin=reference_params['model::nlin'],\n",
    "                    dropout=reference_params['model::dropout']\n",
    "                )\n",
    "                recon_model.load_state_dict(recon_checkpoint)\n",
    "                recon_acc = test_model(recon_model, TESTSET_DL['svhn'])\n",
    "                \n",
    "                # Save results to DataFrame\n",
    "                mdx = bdx * x.shape[0] + idx\n",
    "                df_zoo_acc.loc[len(df_zoo_acc)] = (\n",
    "                    mdx,\n",
    "                    hr_label,\n",
    "                    orig_acc,\n",
    "                    recon_acc\n",
    "                )\n",
    "                df_x.loc[len(df_x)] = [mdx, hr_label] + x[idx].flatten().tolist()\n",
    "                df_z.loc[len(df_z)] = [mdx, hr_label] + z[idx].flatten().tolist()\n",
    "\n",
    "    # Save results to disk\n",
    "    df_zoo_acc.to_csv(DF_ZOO_ACC_PATH)\n",
    "    df_x.to_csv(DF_X_PATH)\n",
    "    df_z.to_csv(DF_Z_PATH)\n",
    "    \n",
    "df_zoo_acc = pd.read_csv(DF_ZOO_ACC_PATH, index_col=0)\n",
    "df_x = pd.read_csv(DF_X_PATH, index_col=0)\n",
    "df_z = pd.read_csv(DF_Z_PATH, index_col=0)\n",
    "df_zoo_acc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3810455b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(len(IDX_DICT['cifar10']), 1, figsize=(8, 4*len(IDX_DICT['cifar10'])))\n",
    "\n",
    "for i, (idx, label) in enumerate(IDX_DICT['cifar10'].items()):\n",
    "    sns.histplot(df_zoo_acc[df_zoo_acc['Hyper-representation model'] == label], x='Original accuracy', stat='probability', binwidth=0.05, binrange=(0., 1.), kde=True, color=COLOURS[0], alpha=0.5, label='Original', ax=axs[i])\n",
    "    sns.histplot(df_zoo_acc[df_zoo_acc['Hyper-representation model'] == label], x='Reconstruction accuracy', stat='probability', binwidth=0.05, binrange=(0., 1.), kde=True, color=COLOURS[1], alpha=0.5, label='Reconstruction', ax=axs[i])\n",
    "    axs[i].set(title=label, xlabel='Test accuracy', ylabel='Probability', ylim=(0, 1))\n",
    "    axs[i].legend()\n",
    "    \n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e79473",
   "metadata": {},
   "source": [
    "### With fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1479e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shrp.models.def_loss import ReconDistillationLoss\n",
    "\n",
    "DF_ZOO_ACC_PATH = EXPERIMENT_PATH / 'df_zoo_ft_acc.csv'\n",
    "DF_Z_PATH = EXPERIMENT_PATH / 'df_z_ft_dict.csv'\n",
    "DF_X_PATH = EXPERIMENT_PATH / 'df_x_ft_dict.csv'\n",
    "\n",
    "N_EPOCHS = 5\n",
    "\n",
    "if not DF_ZOO_ACC_PATH.is_file() or RERUN:\n",
    "    # Create dataframe\n",
    "    df_zoo_acc = pd.DataFrame(columns=['Model index', 'Hyper-representation model', 'Original accuracy', 'Reconstruction accuracy'])\n",
    "    df_x = pd.DataFrame(columns=['Model index', 'Hyper-representation model'] + X_COLS)\n",
    "    df_z = pd.DataFrame(columns=['Model index', 'Hyper-representation model'] + Z_COLS)\n",
    "\n",
    "    # Run experiments\n",
    "    for hr_idx, hr_label in IDX_DICT['cifar10'].items():\n",
    "        hr_model = hyper_reps[hr_idx].to('cuda')\n",
    "        \n",
    "        trainloader = ZOO_DL_TRAIN['svhn']\n",
    "        optimiser = torch.optim.AdamW(hr_model.parameters(), lr=1e-5, weight_decay=3e-9)\n",
    "        criterion = ReconDistillationLoss(reference_checkpoint, reference_params, queryset='data', dump=\"/netscratch2/lmeynent/research/structure_vs_behaviour/results/data/svhn_train_zoo_relu/dataset.pt\", n_queries=256)\n",
    "        \n",
    "        hr_model.train()\n",
    "        for edx in range(N_EPOCHS):\n",
    "            for data in trainloader:\n",
    "                x, m, p, _ = [tensor.to('cuda') for tensor in data]\n",
    "                \n",
    "                optimiser.zero_grad()\n",
    "                _, y, _ = hr_model.forward(x, p)\n",
    "                loss = criterion(y, x, m, p)\n",
    "                loss['loss_recon'].backward()\n",
    "                optimiser.step()\n",
    "        \n",
    "        hr_model.eval()\n",
    "        for bdx, data in enumerate(tqdm(ZOO_DL['svhn'])):\n",
    "            x, m, p, _ = [tensor.to('cuda') for tensor in data]\n",
    "            z, y, _ = hr_model.forward(x, p)\n",
    "            \n",
    "            for idx in range(x.shape[0]):\n",
    "                # Original accuracy\n",
    "                orig_checkpoint = tokens_to_checkpoint(x[idx], p[idx], reference_checkpoint)\n",
    "                orig_model = CNN3(\n",
    "                    channels_in=reference_params['model::channels_in'],\n",
    "                    nlin=reference_params['model::nlin'],\n",
    "                    dropout=reference_params['model::dropout']\n",
    "                )\n",
    "                orig_model.load_state_dict(orig_checkpoint)\n",
    "                orig_acc = test_model(orig_model, TESTSET_DL['svhn'])\n",
    "                \n",
    "                # Reconstruction accuracy\n",
    "                recon_checkpoint = tokens_to_checkpoint(y[idx], p[idx], reference_checkpoint)\n",
    "                recon_model = CNN3(\n",
    "                    channels_in=reference_params['model::channels_in'],\n",
    "                    nlin=reference_params['model::nlin'],\n",
    "                    dropout=reference_params['model::dropout']\n",
    "                )\n",
    "                recon_model.load_state_dict(recon_checkpoint)\n",
    "                recon_acc = test_model(recon_model, TESTSET_DL['svhn'])\n",
    "                \n",
    "                # Save results to DataFrame\n",
    "                mdx = bdx * x.shape[0] + idx\n",
    "                df_zoo_acc.loc[len(df_zoo_acc)] = (\n",
    "                    mdx,\n",
    "                    hr_label,\n",
    "                    orig_acc,\n",
    "                    recon_acc\n",
    "                )\n",
    "                df_x.loc[len(df_x)] = [mdx, hr_label] + x[idx].flatten().tolist()\n",
    "                df_z.loc[len(df_z)] = [mdx, hr_label] + z[idx].flatten().tolist()\n",
    "\n",
    "    # Save results to disk\n",
    "    df_zoo_acc.to_csv(DF_ZOO_ACC_PATH)\n",
    "    df_x.to_csv(DF_X_PATH)\n",
    "    df_z.to_csv(DF_Z_PATH)\n",
    "    \n",
    "df_zoo_acc = pd.read_csv(DF_ZOO_ACC_PATH, index_col=0)\n",
    "df_x = pd.read_csv(DF_X_PATH, index_col=0)\n",
    "df_z = pd.read_csv(DF_Z_PATH, index_col=0)\n",
    "df_zoo_acc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3cdead",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(len(IDX_DICT['cifar10']), 1, figsize=(8, 4*len(IDX_DICT['cifar10'])))\n",
    "\n",
    "for i, (idx, label) in enumerate(IDX_DICT['cifar10'].items()):\n",
    "    sns.histplot(df_zoo_acc[df_zoo_acc['Hyper-representation model'] == label], x='Original accuracy', stat='probability', binwidth=0.05, binrange=(0., 1.), kde=True, color=COLOURS[0], alpha=0.5, label='Original', ax=axs[i])\n",
    "    sns.histplot(df_zoo_acc[df_zoo_acc['Hyper-representation model'] == label], x='Reconstruction accuracy', stat='probability', binwidth=0.05, binrange=(0., 1.), kde=True, color=COLOURS[1], alpha=0.5, label='Reconstruction', ax=axs[i])\n",
    "    axs[i].set(title=label, xlabel='Test accuracy', ylabel='Probability', ylim=(0, 1))\n",
    "    axs[i].legend()\n",
    "    \n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
